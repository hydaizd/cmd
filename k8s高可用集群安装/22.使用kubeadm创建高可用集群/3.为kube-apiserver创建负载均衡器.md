官网文档：https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/high-availability/

---
1.新增haproxy配置:
frontend  kube-api
    bind  0.0.0.0:8443
    mode  tcp   # 配置haproxy用tcp穿透https即haproxy可不用配置证书，注意此处非http模式
    default_backend  kube-client
backend kube-client
    mode  tcp   # 也需要对应设置成tcp，才能不需要证书代理https，否则不能访问
    balance source
    server  k8s-node1 192.168.0.200:6443 check inter 2000 fall 2
    server  k8s-node2 192.168.0.201:6443 check inter 2000 fall 2
    server  k8s-node3 192.168.0.202:6443 check inter 2000 fall 2
---

2.设置 ectd 集群(此处使用的外部etcd)
(1)将以下文件从集群中的任何 etcd 节点复制到第一个控制平面节点(由于我的etcd节点机器和第一个平面节点是同一台机器，可忽略此步骤)：
export CONTROL_PLANE="root@192.168.0.200"
scp /etc/kubernetes/pki/etcd/ca.crt "${CONTROL_PLANE}":
scp /etc/kubernetes/pki/apiserver-etcd-client.crt "${CONTROL_PLANE}":
scp /etc/kubernetes/pki/apiserver-etcd-client.key "${CONTROL_PLANE}":
```
(2)设置第一个控制平面节点，用以下内容创建一个名为 kubeadm-config.yaml 的文件(https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2)：
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: stable
#kubernetesVersion: "v1.17.3"
localAPIEndpoint:
  advertiseAddress: 192.168.0.222
  bindPort: 8443
controlPlaneEndpoint: "192.168.0.222:8443"  # 填写haproxy的漂移ip
networking:
  podSubnet: "192.168.0.0/16" # 必须得指定，并且要与网络插件相对应，如flannel是10.244.0.0/16，calico是192.168.0.0/16
etcd:
    external:
        endpoints:
        - https://192.168.0.200:2379
        - https://192.168.0.201:2379
        - https://192.168.0.202:2379
        caFile: /etc/kubernetes/pki/etcd/ca.crt
        certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
        keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key
```
(3)在节点上运行 sudo kubeadm init --config kubeadm-config.yaml --upload-certs --v=5 命令
- detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd"
可忽略，可附加命令参数：--ignore-preflight-errors=all 忽略 
- /etc/kubernetes/manifests/etcd.yaml already exists
可忽略
- running with swap on is not supported. Please disable swap
关闭swap分区，(1.8版本后的要求，目的应该是不想让swap干扰pod可使用的内存limit)
临时关闭swap分区（重启失效）
swapoff -a
永久关闭swap分区，注释swap
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
-  failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgroupfs"
原来是 kubelet 启动时的 cgroup driver 和 docker 的不一致，修改之前创建的启动文件：/usr/lib/systemd/system/kubelet.service.d/20-etcd-service-manager.conf
将--cgroup-driver=systemd改为：--cgroup-driver=cgroupfs
- Pull image "k8s.gcr.io/kube-scheduler:v1.17.3" failed
通过其他途径下载对应版本的tar包，再通过命令：docker load -i kube-scheduler_v_1_17.3.tar 导入镜像
导出镜像：docker save -o kube-scheduler_v_1_17.3.tar k8s.gcr.io/kube-scheduler:v1.17.3
- Setting node annotation to enable volume controller attach/detach
访问不了：https://192.168.0.222:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0
可以访问：https://192.168.0.222:6443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0
说明是HA代理没有起到作用，导致api-server无法正常访问
解决方法：需要将frontend和对应backend的mode都设置成tcp，则HA可无证书代理https
- error execution phase upload-config/kubelet: Error writing Crisocket information for the control-plane node: timed out waiting for the condition
误配置了/etc/systemd/system/kubelet.service.d/下的20-etcd-service-manager.conf文件，把此文件中的配置：
--address=127.0.0.1 --pod-manifest-path=/etc/kubernetes/manifests，追加到文件/etc/sysconfig/kubelet中，如：
KUBELET_EXTRA_ARGS=--address=127.0.0.1 --pod-manifest-path=/etc/kubernetes/manifests
```
(4)# 初始化当前用户配置 使用kubectl会用到
mkdir -p $HOME/.kube
sudo cp -f /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
---

3.查看集群
(1)kubectl get nodes
